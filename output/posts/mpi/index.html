<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="zh_cn">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>MPI | chimez's blog</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="zh_cn" href="../../rss.xml">
<link rel="canonical" href="https://chimez.github.io/posts/mpi/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="chimez">
<link rel="prev" href="../slepc/" title="SLEPc" type="text/html">
<link rel="next" href="../cython/" title="cython" type="text/html">
<meta property="og:site_name" content="chimez's blog">
<meta property="og:title" content="MPI">
<meta property="og:url" content="https://chimez.github.io/posts/mpi/">
<meta property="og:description" content="MPI: Message Passing Interface


MPI 是消息传递接口标准，主要的实现有 Intel MPI, OpenMPI 和 MPICH 等. MPI 标准目前有三版 MPI-1,MPI-2, MPI-3, 标准支持的语言是 c 和 fortran, c++ 支持在 MPI-3 中移除了。



MPI 的优势：


标准：所有超级计算机都支持
可移植：无需修改程序就能在所">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2021-07-04T17:00:31+08:00">
<meta property="article:tag" content="C">
<meta property="article:tag" content="MPI">
<meta property="article:tag" content="parallel">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">跳到主内容</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">chimez's blog</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.org" id="sourcelink" class="nav-link">源文件</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="../../rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">MPI</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    chimez
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2021-07-04T17:00:31+08:00" itemprop="datePublished" title="2021-07-04 17:00">2021-07-04 17:00</time></a>
            </p>
                <p class="commentline">
    
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/mpi.html">评论</a>


            
        </p>
<p class="sourceline"><a href="index.org" class="sourcelink">源文件</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div id="outline-container-orge32d29f" class="outline-2">
<h2 id="orge32d29f">MPI: Message Passing Interface</h2>
<div class="outline-text-2" id="text-orge32d29f">
<p>
MPI 是消息传递接口标准，主要的实现有 Intel MPI, OpenMPI 和 MPICH 等. MPI 标准目前有三版 MPI-1,MPI-2, MPI-3, 标准支持的语言是 c 和 fortran, c++ 支持在 MPI-3 中移除了。
</p>

<p>
MPI 的优势：
</p>
<ul class="org-ul">
<li>标准：所有超级计算机都支持</li>
<li>可移植：无需修改程序就能在所有支持 MPI 的平台上运行</li>
<li>高性能：所有实现都会根据机器做优化</li>
<li>功能齐全：MPI-3 中有超过 430 个函数，尽管大多数程序可能就用几十个函数</li>
<li>可用：相当多的实现都可用，包括供应商提供的和开放获取的</li>
</ul>
</div>

<div id="outline-container-orgf3b6663" class="outline-3">
<h3 id="orgf3b6663">基本结构</h3>
<div class="outline-text-3" id="text-orgf3b6663">
</div>
<div id="outline-container-org96c6f62" class="outline-4">
<h4 id="org96c6f62">程序结构</h4>
<div class="outline-text-4" id="text-org96c6f62">
<p>
所有 MPI 程序都分以下几步
</p>
<ol class="org-ol">
<li>引用头文件 <code>"mpi.h"</code>
</li>
<li>执行顺序代码</li>
<li>初始化 MPI 环境</li>
<li>执行并行任务</li>
<li>终止 MPI 环境</li>
<li>执行顺序代码</li>
<li>程序结束</li>
</ol>
</div>
</div>

<div id="outline-container-org5e93520" class="outline-4">
<h4 id="org5e93520">接口约定</h4>
<div class="outline-text-4" id="text-org5e93520">
<p>
所有 MPI 的函数都以 <code>MPI_</code> 开头，并且下划线后的第一个字母大写，函数返回消息码 <code>rc</code> , 如果成功就是 <code>MPI_SUCCESS</code>, 即 <code>0</code>
</p>
</div>
</div>

<div id="outline-container-org45faeb4" class="outline-4">
<h4 id="org45faeb4">基本概念</h4>
<div class="outline-text-4" id="text-org45faeb4">
<ol class="org-ol">
<li>
<b>communicator</b>: 通信器，定义哪些进程之间需要通信
<ol class="org-ol">
<li>
<code>MPI_COMM_WORLD</code> 通信器表示所有进程都相互通信</li>
</ol>
</li>
<li>
<b>group</b>: 进程的分组</li>
<li>
<b>rank</b>: 秩，指的是一个通信器中每个进程都有自己单独的编号，有时候也叫做 <b>任务 ID</b> ，秩是从 0 开始连续的整数</li>
<li>
<b>错误处理</b>: 尽管大多数函数都返回一个错误码，但是 MPI 标准指出，当错误发生时程序应立刻终止，所以并不需要自己捕获和处理所有错误码</li>
</ol>
</div>
</div>

<div id="outline-container-org30977cb" class="outline-4">
<h4 id="org30977cb">MPI 版本</h4>
<div class="outline-text-4" id="text-org30977cb">
<p>
<b>MPI-1</b> (1994) ：最早的版本，构建起了 MPI 的基本框架，包括
</p>
<ol class="org-ol">
<li>基本的环境管理</li>
<li>点到点通信</li>
<li>集体通信</li>
<li>组和通信器</li>
<li>虚拟拓扑</li>
</ol>
<p>
<b>MPI-2</b> (1998) ： 为 MPI-1 添加大量新函数
</p>
<ol class="org-ol">
<li>动态进程：可以在任务启动后创建新的进程</li>
<li>单边通信：提供单向通信功能，包括共享内存和远程累加操作</li>
<li>扩展集体通信：允许通信器间的集体通信</li>
<li>扩展接口：允许在 MPI 之上构造开发曾，包括 debugger 和 profiler 等</li>
<li>额外语言绑定：支持 fortran 90</li>
<li>并行 I/O</li>
</ol>
<p>
<b>MPI-3</b> (2012) ：对 MPI-1 和 MPI-2 更多的扩展
</p>
<ol class="org-ol">
<li>非阻塞集体操作</li>
<li>新的单边通信操作</li>
<li>近邻集体：扩展更多虚拟拓扑结构</li>
<li>支持 fortran 2008</li>
<li>MPIT Tool Interface 允许 MPI 实现开放一些内部变量给用户，用于性能提升</li>
<li>Matched Probe: 改进多线程中的 probe 功能</li>
</ol>
<p>
<b>MPI-4</b> (2021) : TODO
</p>
<ol class="org-ol">
<li>增加大 count 参数支持</li>
<li>持久集体</li>
<li>部分通信</li>
<li>新的初始化方式</li>
<li>改进信息和错误处理</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org80f5bdc" class="outline-3">
<h3 id="org80f5bdc">环境管理函数</h3>
<div class="outline-text-3" id="text-org80f5bdc">
<ol class="org-ol">
<li>
<code>MPI_Init (&amp;argc,&amp;argv)</code>
<ol class="org-ol">
<li>初始化 MPI 环境，应在所有 MPI 函数之前调用，并且只能调用一次，这个函数具体做的事情是实现依赖的</li>
</ol>
</li>
<li>
<code>MPI_Comm_size (comm,&amp;size)</code>
<ol class="org-ol">
<li>获得通信器 <code>comm</code> 中 MPI 进程的总数</li>
<li>如果通信器是 <code>MPI_COMM_WORLD</code> 那么就会得到程序的总进程数</li>
</ol>
</li>
<li>
<code>MPI_Comm_rank (comm,&amp;rank)</code>
<ol class="org-ol">
<li>获得调用这个函数的进程在通信器 <code>comm</code> 中的秩，</li>
</ol>
</li>
<li>
<code>MPI_Abort (comm,errorcode)</code>
<ol class="org-ol">
<li>终止通信器 <code>comm</code> 中的所有进程</li>
</ol>
</li>
<li>
<code>MPI_Get_processor_name (&amp;name,&amp;resultlength)</code>
<ol class="org-ol">
<li>获得进程的名字和名字的长度</li>
<li>名字的缓冲区大小至少是 <code>MPI_MAX_PROCESSOR_NAME</code> 个 <code>sizeof(char)</code>
</li>
<li>具体返回的名字是什么是实现依赖的</li>
</ol>
</li>
<li>
<code>MPI_Get_version (&amp;version,&amp;subversion)</code>
<ol class="org-ol">
<li>获得 MPI 标准的版本号和子版本号</li>
</ol>
</li>
<li>
<code>MPI_Initialized (&amp;flag)</code>
<ol class="org-ol">
<li>测试是否已经调用过 <code>MPI_Init()</code>
</li>
</ol>
</li>
<li>
<code>MPI_Wtime ()</code>
<ol class="org-ol">
<li>返回该进程所处的时间，以秒为单位</li>
<li>不同进程的时间可能不一样，但大多数实现会同步这个时间</li>
</ol>
</li>
<li>
<code>MPI_Wtick ()</code>
<ol class="org-ol">
<li>返回 <code>MPI_Wtime()</code> 的精度</li>
</ol>
</li>
<li>
<code>MPI_Finalize ()</code>
<ol class="org-ol">
<li>终止 MPI 环境，每个 MPI 程序只能调用一次</li>
</ol>
</li>
</ol>
<div class="highlight"><pre><span></span><span class="w">   </span><span class="cp">#include</span><span class="w"> </span><span class="cpf">"mpi.h"</span>

<span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="w">   </span><span class="p">{</span>
<span class="w">       </span><span class="n">MPI_Init</span><span class="p">(</span><span class="o">&amp;</span><span class="n">argc</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">argv</span><span class="p">);</span>

<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">num_tasks</span><span class="p">;</span>
<span class="w">       </span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">num_tasks</span><span class="p">);</span>

<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">rank</span><span class="p">;</span>
<span class="w">       </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">rank</span><span class="p">);</span>

<span class="w">       </span><span class="kt">char</span><span class="w"> </span><span class="n">hostname</span><span class="p">[</span><span class="n">MPI_MAX_PROCESSOR_NAME</span><span class="p">];</span>
<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">name_len</span><span class="p">;</span>
<span class="w">       </span><span class="n">MPI_Get_processor_name</span><span class="p">(</span><span class="n">hostname</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">name_len</span><span class="p">);</span>

<span class="w">       </span><span class="n">MPI_Finalize</span><span class="p">();</span>
<span class="w">   </span><span class="p">}</span>
</pre></div>
</div>
</div>

<div id="outline-container-org7d2ce5d" class="outline-3">
<h3 id="org7d2ce5d">点到点通信</h3>
<div class="outline-text-3" id="text-org7d2ce5d">
</div>
<div id="outline-container-org2ac499e" class="outline-4">
<h4 id="org2ac499e">一般参数说明</h4>
<div class="outline-text-4" id="text-org2ac499e">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<colgroup>
<col class="org-left">
<col class="org-left">
</colgroup>
<thead><tr>
<th scope="col" class="org-left">类型</th>
<th scope="col" class="org-left">举例的函数</th>
</tr></thead>
<tbody>
<tr>
<td class="org-left">Blocking sends</td>
<td class="org-left">MPI<sub>Send</sub>(buffer,count,type,dest,tag,comm)</td>
</tr>
<tr>
<td class="org-left">Non-blocking sends</td>
<td class="org-left">MPI<sub>Isend</sub>(buffer,count,type,dest,tag,comm,request)</td>
</tr>
<tr>
<td class="org-left">Blocking receive</td>
<td class="org-left">MPI<sub>Recv</sub>(buffer,count,type,source,tag,comm,status)</td>
</tr>
<tr>
<td class="org-left">Non-blocking receive</td>
<td class="org-left">MPI<sub>Irecv</sub>(buffer,count,type,source,tag,comm,request)</td>
</tr>
</tbody>
</table>
<p>
参数说明：
</p>
<ol class="org-ol">
<li>
<b>buffer</b>: 要被收发的内容，内存地址，也就是指针</li>
<li>
<b>count</b>: 要收发的数据大小</li>
<li>
<b>type</b>: 数据类型，全大写的一个量 <code>MPI_CHAR</code> 等，也可以自定义</li>
<li>
<b>destination</b>: 发送的目标进程的 rank</li>
<li>
<b>source</b>: 接受的源进程的 rank，
<ol class="org-ol">
<li>如果是 <code>MPI_ANY_SOURCE</code> 那么就从所有进程接收</li>
</ol>
</li>
<li>
<b>tag</b>: 一个任意的非负整数参数，用来标记不同的信息，接收和发送两方的 <code>tag</code> 要相同，
<ol class="org-ol">
<li>
<code>MPI_ANY_TAG</code> 会接收所有 tag</li>
<li>MPI 标准指出 tag 应该在 0-32767, 不过大多数实现都支持更大的数</li>
</ol>
</li>
<li>
<b>comm</b>: 通信器</li>
<li>
<b>status</b>: 是收到的消息的属性，类型是 <code>MPI_Status</code>
<ol class="org-ol">
<li>
<code>MPI_Get_count()</code> 可以获取收到的消息的大小</li>
</ol>
</li>
<li>
<b>request</b>: 非阻塞收发的回调，类型是 <code>MPI_Request</code>
</li>
</ol>
</div>
</div>

<div id="outline-container-orgfc67bd7" class="outline-4">
<h4 id="orgfc67bd7">常用阻塞点到点通信函数</h4>
<div class="outline-text-4" id="text-orgfc67bd7">
<ol class="org-ol">
<li>
<code>MPI_Send()</code> 基本的发送消息, 只有当发送信道再次可用时才返回</li>
<li>
<code>MPI_Recv()</code> 基本的接收消息，阻塞直到接收信道再次可用</li>
<li>
<code>MPI_Ssend()</code> 同步阻塞发送，阻塞直到发送信道可用并且接收方开始接收这个消息</li>
<li>
<code>MPI_Sendrecv()</code> 发送消息并发送回执，阻塞直到发送信道可用，并且接收方已经收到消息</li>
<li><code>MPI_Wait()</code></li>
<li><code>MPI_Waitany()</code></li>
<li><code>MPI_Waitall()</code></li>
<li>
<code>MPI_Waitsome()</code>
<ol class="org-ol">
<li>阻塞直到某个非阻塞的收发完成</li>
</ol>
</li>
<li>
<code>MPI_Probe()</code> 进行阻塞测试</li>
<li>
<code>MPI_Get_count()</code> 返回收到的消息的源、标签和大小
<ol class="org-ol">
<li>输出类型是 <code>MPI_SOURCE</code>
</li>
</ol>
</li>
</ol>
</div>
</div>

<div id="outline-container-org5adabde" class="outline-4">
<h4 id="org5adabde">常用非阻塞点到点通信函数</h4>
<div class="outline-text-4" id="text-org5adabde">
<ol class="org-ol">
<li>
<code>MPI_Isend()</code> 非阻塞发送，所指定的发送 buffer 应该在 <code>MPI_Probe()</code> 确定已经发送完成之前不修改</li>
<li>
<code>MPI_Irecv()</code> 非阻塞接收，同样不应该在确定接收完成前修改 buffer</li>
<li>
<code>MPI_Issend()</code> 非阻塞同步发送，类似 <code>MPI_Isend()</code> 只是 <code>MPI_Probe()</code> 会确定接收方已经收到消息</li>
<li><code>MPI_Test()</code></li>
<li><code>MPI_Testany()</code></li>
<li><code>MPI_Testall()</code></li>
<li>
<code>MPI_Testsome()</code>
<ol class="org-ol">
<li>检查非阻塞收发操作的状态，输出值 <code>flag</code> 为 <code>0</code> 表示没完成， <code>1</code> 表示已完成</li>
</ol>
</li>
<li>
<code>MPI_Iprobe()</code> 进行非阻塞测试, 如果消息已经到了 <code>flag</code> 为 <code>1</code>
</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org9eae9af" class="outline-3">
<h3 id="org9eae9af">集体通信</h3>
<div class="outline-text-3" id="text-org9eae9af">

<div id="org8235f9e" class="figure">
<p><img src="../../img/MPI:_Message_Passing_Interface/2021-07-04_18-47-40_collective_comm.gif" alt="nil"></p>
</div>

<p>
集体通信操作的类型有
</p>
<ul class="org-ul">
<li>
<b>同步</b> 阻塞直到所有进程都到达同步点</li>
<li>
<b>数据移动</b> broadcast, scatter, gather, all to all</li>
<li>
<b>集体计算(归约)</b> min, max, add, multiply 等</li>
</ul>
</div>

<div id="outline-container-orge2210be" class="outline-4">
<h4 id="orge2210be">常用集体通信函数</h4>
<div class="outline-text-4" id="text-orge2210be">
<ol class="org-ol">
<li>
<code>MPI_Barrier (comm)</code> 同步所有进程</li>
<li>
<code>MPI_Bcast (&amp;buffer,count,datatype,root,comm)</code> 将数据从 <code>root</code> 进程广播到所有进程</li>
<li>
<code>MPI_Scatter (&amp;sendbuf,sendcnt,sendtype,&amp;recvbuf,recvcnt,recvtype,root,comm)</code> 将数据分散到所有进程</li>
<li>
<code>MPI_Gather (&amp;sendbuf,sendcnt,sendtype,&amp;recvbuf,recvcount,recvtype,root,comm)</code> 从所有进程获取数据到 <code>root</code>
</li>
<li>
<code>MPI_Allgather (&amp;sendbuf,sendcount,sendtype,&amp;recvbuf,recvcount,recvtype,comm)</code> 所有进程都获得总的数据</li>
<li>
<code>MPI_Reduce (&amp;sendbuf,&amp;recvbuf,count,datatype,op,root,comm)</code> 执行一个归约操作 <code>op</code> 到进程 <code>root</code>
</li>
<li>
<code>MPI_Allreduce (&amp;sendbuf,&amp;recvbuf,count,datatype,op,comm)</code> 执行归约操作到所有进程</li>
<li>
<code>MPI_Reduce_scatter (&amp;sendbuf,&amp;recvbuf,recvcount,datatype,op,comm)</code> 先 reduce 再 scatter</li>
<li>
<code>MPI_Alltoall (&amp;sendbuf,sendcount,sendtype,&amp;recvbuf,recvcnt,recvtype,comm)</code> 每个进程都执行 scatter</li>
<li>
<code>MPI_Scan (&amp;sendbuf,&amp;recvbuf,count,datatype,op,comm)</code> 扫描操作</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-orgc9a4ddd" class="outline-3">
<h3 id="orgc9a4ddd">自定义数据类型</h3>
<div class="outline-text-3" id="text-orgc9a4ddd">
<p>
用户定义的数据类型，称作 <b>derived data types</b>
</p>

<ol class="org-ol">
<li>
<code>MPI_Type_contiguous (count,oldtype,&amp;newtype)</code> 创建一个新的数据类型，是 <code>count</code> 个旧类型数据的组合</li>
<li>
<code>MPI_Type_vector (count,blocklength,stride,oldtype,&amp;newtype)</code> 与 <code>MPI_Type_contiguous</code> 相同，只不过每个数据间可以有间隔</li>
<li><code>MPI_Type_indexed (count,blocklens[],offsets[],old_type,&amp;newtype)</code></li>
<li><code>MPI_Type_create_struct</code></li>
<li><code>MPI_Type_get_extent</code></li>
<li>
<code>MPI_Type_commit (&amp;datatype)</code> 向系统提交类型</li>
<li>
<code>MPI_Type_free (&amp;datatype)</code> 释放指定类型的对象</li>
</ol>
</div>

<div id="outline-container-orge5c66df" class="outline-4">
<h4 id="orge5c66df">自定义结构体</h4>
<div class="outline-text-4" id="text-orge5c66df">
<p>
<code>MPI_Type_create_struct(count, array_of_blocklengths, array_of_displacements, array_of_types, newtype)</code>
</p>
<ol class="org-ol">
<li>
<code>count</code> 结构体中的元素数，也是下面三个数组的长度</li>
<li>
<code>array_of_blocklengths</code> 每个块中的元素个数</li>
<li>
<code>array_of_displacements</code> 每个块的偏移量</li>
<li>
<code>array_of_types</code> 每个块的类型</li>
<li>
<code>newtype</code> 输出</li>
</ol>
<div class="highlight"><pre><span></span><span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">object</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="kt">char</span><span class="w"> </span><span class="n">c</span><span class="p">;</span>
<span class="w">        </span><span class="kt">double</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="w">        </span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="p">;</span>
<span class="w">    </span><span class="p">};</span>

<span class="w">    </span><span class="n">MPI_Datatype</span><span class="w"> </span><span class="n">newtype</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">object_len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">blocklengths</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">    </span><span class="n">MPI_Datatype</span><span class="w"> </span><span class="n">types</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="w">    </span><span class="n">MPI_Aint</span><span class="w"> </span><span class="n">displacements</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>

<span class="w">    </span><span class="n">MPI_Aint</span><span class="w"> </span><span class="n">current_displacement</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="n">blocklength</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">types</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MPI_CHAR</span><span class="p">;</span>
<span class="w">    </span><span class="n">displacements</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">offsetof</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">object</span><span class="p">,</span><span class="w"> </span><span class="n">c</span><span class="p">);</span>

<span class="w">    </span><span class="n">blocklength</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">;</span>
<span class="w">    </span><span class="n">types</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MPI_DOUBLE</span><span class="p">;</span>
<span class="w">    </span><span class="n">displacements</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">offsetof</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">object</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">);</span>

<span class="w">    </span><span class="n">blocklength</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="n">types</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">;</span>
<span class="w">    </span><span class="n">displacements</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">offsetof</span><span class="p">(</span><span class="k">struct</span><span class="w"> </span><span class="nc">object</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">);</span>

<span class="w">    </span><span class="n">MPI_Type_create_struct</span><span class="p">(</span><span class="n">object_len</span><span class="p">,</span><span class="w"> </span><span class="n">blocklengths</span><span class="p">,</span><span class="w"> </span><span class="n">displacements</span><span class="p">,</span><span class="w"> </span><span class="n">types</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">newtype</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Type_commit</span><span class="p">(</span><span class="o">&amp;</span><span class="n">newtype</span><span class="p">);</span>

<span class="w">    </span><span class="k">struct</span><span class="w"> </span><span class="nc">object</span><span class="w"> </span><span class="n">o</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">proc_id</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">){</span>
<span class="w">        </span><span class="n">MPI_Send</span><span class="p">(</span><span class="o">&amp;</span><span class="n">o</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">newtype</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">comm</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">proc_id</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">1</span><span class="p">){</span>
<span class="w">        </span><span class="n">MPI_Recv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">o</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">newtype</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">MPI_Type_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">newtype</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>

<div id="outline-container-org419df78" class="outline-3">
<h3 id="org419df78">组和通信器管理</h3>
<div class="outline-text-3" id="text-org419df78">
<p>
<b>group</b> 组是一些进程的有序集合，每个进程编号从 0 到 N-1, <b>communicator</b> 通信器是一组需要相互通信的进程，每个组都有一个通信器。从编程的角度看，组是用来指定哪些进程相互通信，进而创建通信器的。
</p>

<p>
典型的过程：
</p>
<ol class="org-ol">
<li>使用 <code>MPI_Comm_group()</code> 从 <code>MPI_COMM_WORLD</code> 中取出全局组的句柄</li>
<li>使用 <code>MPI_Group_incl()</code> 从全局组的子集中创建新的组</li>
<li>使用 <code>MPI_Comm_create()</code> 为新的组创建通信器</li>
<li>使用 <code>MPI_Comm_rank()</code> 确定新的通信器中的 rank</li>
<li>进行通信</li>
<li>使用 <code>MPI_Comm_free()</code> 和 <code>MPI_Group_free()</code> 释放不用的组和通信器对象</li>
</ol>
</div>

<div id="outline-container-orga0fdaa3" class="outline-4">
<h4 id="orga0fdaa3">基本通信器</h4>
<div class="outline-text-4" id="text-orga0fdaa3">
<ul class="org-ul">
<li>
<code>MPI_COMM_WORLD</code> 全部的进程</li>
<li>
<code>MPI_COMM_SELF</code> 只包含当前进程</li>
<li>
<code>MPI_COMM_NULL</code> 无效通信器，用于一些函数的错误码</li>
</ul>
<p>
通信器的类型是 <code>MPI_Comm</code>
</p>
</div>
</div>

<div id="outline-container-orgaeaab25" class="outline-4">
<h4 id="orgaeaab25">复制通信器</h4>
<div class="outline-text-4" id="text-orgaeaab25">
<p>
复制一个一样的通信器，主要用于库函数编写时防止修改全局参数    
</p>

<ol class="org-ol">
<li>
<code>MPI_Comm_dup()</code> 复制一个通信器</li>
<li>
<code>MPI_Comm_idup()</code> 复制通信器，非阻塞</li>
<li>
<code>MPI_Comm_dup_with_info()</code> 复制通信器并传递 info</li>
<li>
<code>MPI_Comm_idup_with_info()</code> 复制通信器并传递 info, 非阻塞</li>
</ol>
</div>
</div>

<div id="outline-container-orgfdfa2f3" class="outline-4">
<h4 id="orgfdfa2f3">划分通信器</h4>
<div class="outline-text-4" id="text-orgfdfa2f3">
<p>
使用 <code>MPI_Comm_split(comm, color, key, newcomm)</code>  将 <code>comm</code> 中有相同 <code>color</code> 的进程组成一个新的通信器 <code>newcomm</code>, 新通信器中的 rank 由 <code>key</code> 指定
</p>

<p>
注意
</p>
<ol class="org-ol">
<li>代码会在所有进程中执行，所以只要进程中生成自己的 <code>color</code> 和 <code>key</code> ,返回的通信器就包括这些进程</li>
<li>一般新通信器中的 <code>rank</code> 跟全局的保存一致就行了， <code>MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_key)</code>
</li>
<li><code>MPI_Comm_spawn()</code></li>
<li><code>MPI_Comm_free()</code></li>
</ol>
</div>
</div>

<div id="outline-container-org839eba1" class="outline-4">
<h4 id="org839eba1">从组创建通信器</h4>
<div class="outline-text-4" id="text-org839eba1">
<p>
组的类型是 <code>MPI_Group</code>
</p>

<ol class="org-ol">
<li><code>MPI_Comm_group()</code></li>
<li>
<code>MPI_Group_incl(group, n, ranks, newgroup)</code> 将组中 <code>ranks</code> 的进程添加到新组</li>
<li>
<code>MPI_Group_excl(group, n, ranks, newgroup)</code> 除了 <code>ranks</code> 以外的进程添加到新组</li>
<li><code>MPI_Group_difference()</code></li>
<li><code>MPI_Group_union()</code></li>
<li><code>MPI_Group_intersection()</code></li>
<li><code>MPI_Group_difference()</code></li>
<li><code>MPI_Group_size()</code></li>
<li><code>MPI_Group_rank()</code></li>
<li><code>MPI_Comm_create_group()</code></li>
<li>
<code>MPI_Comm_create(comm, group, newcomm)</code> 从组创建通信器</li>
</ol>
</div>
</div>

<div id="outline-container-org40e446e" class="outline-4">
<h4 id="org40e446e">通信器间的通信器</h4>
<div class="outline-text-4" id="text-org40e446e">
<p>
<code>MPI_Intercomm_create(local_comm, local_leader, peer_comm, remote_leader, tag, newintercomm)</code>
</p>
</div>
</div>
</div>

<div id="outline-container-orgb6c0c83" class="outline-3">
<h3 id="orgb6c0c83">虚拟拓扑</h3>
<div class="outline-text-3" id="text-orgb6c0c83">
<p>
MPI 的术语 <b>virtual topologies</b> 指的是一些进程相互连接构成一个几何形状，这个网络拓扑是虚拟的，与物理实际的连接无关。
</p>

<p>
当特殊的通信模式与一个拓扑结果相匹配时 MPI 虚拟拓扑就很有用了。
</p>
</div>
</div>

<div id="outline-container-orgaa8938a" class="outline-3">
<h3 id="orgaa8938a">单边通信</h3>
<div class="outline-text-3" id="text-orgaa8938a">
</div>
<div id="outline-container-org319f964" class="outline-4">
<h4 id="org319f964">基本概念</h4>
<div class="outline-text-4" id="text-org319f964">
<ul class="org-ul">
<li>Remote Memory Access(RMA), Remote Direct Momory Access (RDMA), 远程内存访问
<ul class="org-ul">
<li>指的是两个进程 origin 和 target, origin 发起动作 put/get, 访问 target 的内存</li>
<li>之所以叫单边通信，是因为 target 进程完全不知道发生了什么</li>
</ul>
</li>
<li>window
<ul class="org-ul">
<li>单边通信只能访问 target 进程所指定的一块内存，称为 window</li>
</ul>
</li>
<li>distributed shared memory, virtual shared memory
<ul class="org-ul">
<li>是除了 window 之外的另一种实现远程内存访问的方法</li>
<li>只有所谓的 Partitioned Global Address Space(PGAS)语言支持，例如 Unified Parallel C (UPC)</li>
</ul>
</li>
<li>active RMA 和 passive RMA
<ul class="org-ul">
<li>active RMA 也叫做 active target synchronization, target 进程设置一个时间周期(epoch)，在这其中 window 可以被访问，类似于同步数据转移</li>
<li>passive RMA 也叫做 passive target synchronization, target 进程不对 window 的访问做限制，这种方式很高效，但是非常难 debug 并且很容易死锁</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgbf3954e" class="outline-4">
<h4 id="orgbf3954e">窗口</h4>
<div class="outline-text-4" id="text-orgbf3954e">
<p>
用于单边通信的内存区域就是窗口，变量类型为 <code>MPI_Win</code>, 进程可以向其中存取任何东西
</p>

<p>
说明
</p>
<ol class="org-ol">
<li>窗口是定义在通信器上的，创建窗口操作是集体通信，即窗口的不同部分被不同的进程所拥有</li>
<li>每个进程的窗口大小独立设置，可以设为 0</li>
<li>窗口的内存分配和释放要显式进行</li>
</ol>
<p>
常用函数
</p>
<ol class="org-ol">
<li>
<code>MPI_Win_allocate()</code> 分配窗口的内存</li>
<li>
<code>MPI_Win_free()</code> 释放内存</li>
<li>
<code>MPI_Win_create()</code> 基于指定的 buffer 创建窗口</li>
<li>
<code>MPI_Win_allocate_shared()</code> 在共享内存的通信器上创建窗口</li>
<li>
<code>MPI_Win_create_dynamic()</code> 创建窗口，但不分配内存</li>
</ol>
<div class="highlight"><pre><span></span><span class="w">    </span><span class="n">MPI_Info</span><span class="w"> </span><span class="n">info</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Win</span><span class="w"> </span><span class="n">window</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Win_allocate</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="n">disp_unit</span><span class="p">,</span><span class="w"> </span><span class="n">info</span><span class="p">,</span><span class="w"> </span><span class="n">comm</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">memory</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">window</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 进行操作 */</span>

<span class="w">    </span><span class="n">MPI_Win_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">window</span><span class="p">);</span>
</pre></div>
</div>
</div>

<div id="outline-container-org6440ef2" class="outline-4">
<h4 id="org6440ef2">动态分配内存</h4>
<div class="outline-text-4" id="text-org6440ef2">
<ol class="org-ol">
<li>
<code>MPI_Win_create_dynamic(MPI_Info info, MPI_Comm comm, MPI_Win *win)</code>
<ol class="org-ol">
<li>创建窗口，可以向其中动态的加入内存</li>
</ol>
</li>
<li>
<code>int MPI_Win_free(MPI_Win *win)</code>
<ol class="org-ol">
<li>释放窗口的内存</li>
</ol>
</li>
<li>
<code>int MPI_Alloc_mem(MPI_Aint size, MPI_Info info, void *baseptr)</code>
<ol class="org-ol">
<li>分配内存</li>
<li>
<code>size</code> 是内存大小</li>
<li>
<code>baseptr</code> 是输出的指针</li>
<li>
<code>info</code> 可以是 <code>MPI_INFO_NULL</code>
</li>
</ol>
</li>
<li>
<code>int MPI_Free_mem(void *base)</code>
<ol class="org-ol">
<li>释放分配的内存</li>
</ol>
</li>
<li>
<code>MPI_Win_attach(MPI_Win win, void *base, MPI_Aint size)</code>
<ol class="org-ol">
<li>向窗口中添加内存</li>
<li>
<code>win</code> 必须是 <code>MPI_Win_create_dynamic()</code> 创建的窗口</li>
<li>窗口中的内存就是这里指针的内存，没有复制</li>
</ol>
</li>
<li>
<code>MPI_Win_detach(MPI_Win win, void *base)</code>
<ol class="org-ol">
<li>从窗口中去掉添加的内存</li>
</ol>
</li>
<li>
<code>int MPI_Win_lock(int lock_type, int rank, int assert, MPI_Win win)</code>
<ol class="org-ol">
<li>对窗口整体加锁</li>
<li>
<code>lock_type</code> 是 <code>MPI_LOCK_EXCLUSIVE</code> 或 <code>MPI_LOCK_SHARED</code>
</li>
<li>
<code>rank</code> 是获得锁的进程</li>
<li>
<code>assert</code> 是用于做优化的参数，不需要就设 <code>assert=0</code>
</li>
</ol>
</li>
<li>
<code>int MPI_Win_unlock(int rank, MPI_Win win)</code>
<ol class="org-ol">
<li>解锁</li>
</ol>
</li>
<li>
<code>int MPI_Get_address(const void *location, MPI_Aint *address)</code>
<ol class="org-ol">
<li>获得调用内存中位置的地址</li>
<li>应该用这个函数获得的 <code>MPI_Alloc_mem()</code> 分配的地址作为值广播给其它需要用到这个值的进程</li>
<li>对于在窗口中的指针，这里获得的地址就是偏移量</li>
<li>可以把偏移量看做是窗口中的指针</li>
</ol>
</li>
<li>
<code>MPI_Put(const void *origin_addr, int origin_count, MPI_Datatype origin_datatype, int target_rank, MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype, MPI_Win win)</code>
<ol class="org-ol">
<li>从 <code>origin_addr</code> 复制内存到 <code>target_rank</code> 进程的从 <code>win</code> 窗口的偏移 <code>target_disp</code> 开始的地址</li>
</ol>
</li>
<li>
<code>MPI_Get(void *origin_addr, int origin_count, MPI_Datatype origin_datatype, int target_rank, MPI_Aint target_disp, int target_count, MPI_Datatype target_datatype, MPI_Win win)</code>
<ol class="org-ol">
<li>从 <code>target_rank</code> 进程的 <code>win</code> 窗口偏移 <code>target_disp</code> 复制内存到 <code>origin_addr</code>
</li>
</ol>
</li>
<li>
<code>int MPI_Compare_and_swap(const void *origin_addr, const void *compare_addr, void *result_addr, MPI_Datatype datatype, int target_rank, MPI_Aint target_disp, MPI_Win win)</code>
<ol class="org-ol">
<li>比较并交换，原子操作</li>
<li>比较当前内存中的旧值 <code>*result_addr</code> 和之前读取到的旧值 <code>*compare_addr</code> ，如果一样，则说明中间内存未被修改过，那么就用新值 <code>*origin_addr</code> 替换旧值 <code>*result_addr</code>
</li>
<li>被修改的值属于 <code>target_rank</code> 进程</li>
<li>
<code>target_disp</code> 是从窗口的起点到 <code>target_rank</code> 进程中被替换的内存 <code>result_addr</code> 的起点之间的偏移量</li>
</ol>
</li>
<li>
<code>int MPI_Win_fence(int assert, MPI_Win win)</code>
<ol class="org-ol">
<li>同步窗口在所有进程中</li>
</ol>
</li>
</ol>
<p>
参考：
</p>
<ol class="org-ol">
<li>这里实现了一个链表 <a href="https://svn.mcs.anl.gov/repos/mpi/mpich2/trunk/test/mpi/rma/linked_list.c">https://svn.mcs.anl.gov/repos/mpi/mpich2/trunk/test/mpi/rma/linked_list.c</a>
</li>
<li>指针的内存要在进程中自己释放，窗口中实际没有保存数据</li>
</ol>
<p>
例子
</p>

<div class="highlight"><pre><span></span><span class="w">    </span><span class="cm">/* 创建窗口 */</span>
<span class="w">    </span><span class="n">MPI_Win</span><span class="w"> </span><span class="n">win</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Win_create_dynamic</span><span class="p">(</span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 分配内存，并把它附加到窗口中，同时获得窗口中对应的偏移量，也就是窗口中的指针 */</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">i_ptr</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Alloc_mem</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">i_ptr</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_attach</span><span class="p">(</span><span class="n">win</span><span class="p">,</span><span class="w"> </span><span class="n">i_ptr</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="n">MPI_Aint</span><span class="w"> </span><span class="n">i_disp</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Get_address</span><span class="p">(</span><span class="n">i_ptr</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">i_disp</span><span class="p">);</span>

<span class="w">    </span><span class="o">*</span><span class="n">i_ptr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">;</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">"%d, i_ptr=%p, %d, i_disp=%ld</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">i_ptr</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">i_ptr</span><span class="p">,</span><span class="w"> </span><span class="n">i_disp</span><span class="p">);</span>

<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">"i ptr dead</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 读数据 */</span>
<span class="w">    </span><span class="n">MPI_Win_lock</span><span class="p">(</span><span class="n">MPI_LOCK_EXCLUSIVE</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">get</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Get</span><span class="p">(</span><span class="o">&amp;</span><span class="n">get</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">i_disp</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">"%d: get= %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">get</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_unlock</span><span class="p">(</span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 写数据 */</span>
<span class="w">    </span><span class="n">MPI_Win_lock</span><span class="p">(</span><span class="n">MPI_LOCK_EXCLUSIVE</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">put</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">proc_rank</span><span class="o">+</span><span class="mi">10</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Put</span><span class="p">(</span><span class="o">&amp;</span><span class="n">put</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">i_disp</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_unlock</span><span class="p">(</span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 同步 */</span>
<span class="w">    </span><span class="n">MPI_Win_fence</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>

<span class="w">    </span><span class="n">MPI_Win_lock</span><span class="p">(</span><span class="n">MPI_LOCK_EXCLUSIVE</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="n">get</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Get</span><span class="p">(</span><span class="o">&amp;</span><span class="n">get</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">i_disp</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>
<span class="w">    </span><span class="n">printf</span><span class="p">(</span><span class="s">"%d: get again= %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">get</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_unlock</span><span class="p">(</span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 释放内存时，要用本地指针释放 */</span>
<span class="w">    </span><span class="n">MPI_Free_mem</span><span class="p">(</span><span class="n">i_ptr</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">win</span><span class="p">);</span>
</pre></div>
</div>
</div>

<div id="outline-container-org73ed907" class="outline-4">
<h4 id="org73ed907">共享内存</h4>
<div class="outline-text-4" id="text-org73ed907">
<ol class="org-ol">
<li>
<code>int MPI_Comm_split_type(MPI_Comm comm, int split_type, int key, MPI_Info info, MPI_Comm *newcomm)</code>
<ol class="org-ol">
<li>获得同一节点上的进程的通信器</li>
<li><code>split_type = MPI_COMM_TYPE_SHARED</code></li>
<li><code>comm = MPI_COMM_WORLD</code></li>
<li><code>key = proc_rank_world</code></li>
</ol>
</li>
<li>
<code>int MPI_Win_allocate_shared (MPI_Aint size, int disp_unit, MPI_Info info, MPI_Comm comm, void *baseptr, MPI_Win *win)</code>
<ol class="org-ol">
<li>创建共享内存数据</li>
<li>
<code>size</code> 是数据的比特大小，即 个数 * sizeof(type)</li>
<li>
<code>disp_unit</code> 是单个数据的比特大小，即 sizeof(type)</li>
<li>
<code>baseptr</code> 是本地数据的指针</li>
<li>这个内存会在 <code>MPI_Win_free()</code> 时释放掉</li>
</ol>
</li>
<li>
<code>int MPI_Win_shared_query (MPI_Win win, int rank, MPI_Aint *size, int *disp_unit, void *baseptr)</code>
<ol class="org-ol">
<li>获得属于 <code>rank</code> 进程的内存在当前进程中的地址</li>
<li>
<code>size</code> win 大小</li>
<li>
<code>disp_unit</code> 单位数据大小</li>
<li>
<code>baseptr</code> 当前进程中用来访问这个内存的指针</li>
</ol>
</li>
</ol>
<div class="highlight"><pre><span></span><span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_rank</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 获得同一节点上的通信器，以及对应的 rank */</span>
<span class="w">    </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm_node</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank_node</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Comm_split_type</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">comm_node</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm_node</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_rank_node</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 获得不同节点上编号为 0 的进程之间的通信器 */</span>
<span class="w">    </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm_0</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank_0</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Comm_split</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank_node</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">comm_0</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm_0</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank_0</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 分配内存, 只有编号为 0 的进程才分配，其它进程的大小是 0 */</span>
<span class="w">    </span><span class="kt">int</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Win</span><span class="w"> </span><span class="n">data_win</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">win_size</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">proc_rank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">){</span>
<span class="w">        </span><span class="n">win_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">win_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">MPI_Win_allocate_shared</span><span class="p">(</span><span class="n">win_size</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="n">comm_node</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">data_win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 在全局编号 0 的进程上创建数据 */</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">proc_rank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">){</span>
<span class="w">        </span><span class="o">*</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">    </span><span class="p">}</span>

<span class="w">    </span><span class="n">MPI_Barrier</span><span class="p">(</span><span class="n">comm_node</span><span class="p">);</span>
<span class="w">    </span><span class="n">MPI_Win_fence</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">data_win</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 分享数据给所有节点上编号 0 的进程 */</span>
<span class="w">    </span><span class="n">MPI_Bcast</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">comm_0</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 其它进程获得节点编号 0 进程上的指针 */</span>
<span class="w">    </span><span class="n">MPI_Aint</span><span class="w"> </span><span class="n">size</span><span class="p">;</span>
<span class="w">    </span><span class="kt">int</span><span class="w"> </span><span class="n">disp_uint</span><span class="p">;</span>
<span class="w">    </span><span class="n">MPI_Win_shared_query</span><span class="p">(</span><span class="n">data_win</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">size</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">disp_unit</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">data_0</span><span class="p">);</span>

<span class="w">    </span><span class="cm">/* 释放内存 */</span>
<span class="w">    </span><span class="n">MPI_Win_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data_win</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>

<div id="outline-container-orgc6b285c" class="outline-3">
<h3 id="orgc6b285c">混合多线程</h3>
<div class="outline-text-3" id="text-orgc6b285c">
<p>
混合多线程的策略：
</p>
<ol class="org-ol">
<li>纯 MPI</li>
<li>每个节点一个 MPI 进程，全部的线程</li>
<li>每个 socket 一个 MPI 进程，和剩下的线程，比如20核的节点，每个节点两个进程，每个进程10线程</li>
</ol>
<p>
大量实践认为混合多线程并不会比纯 MPI 速度快。
</p>
</div>

<div id="outline-container-org0d8d190" class="outline-4">
<h4 id="org0d8d190">线程初始化</h4>
<div class="outline-text-4" id="text-org0d8d190">
<p>
使用 <code>MPI_Init_thread()</code> 初始化带有线程的 MPI，可用的选项有（注意并不是所有MPI实现都提供下面全部的模式）
</p>
<ol class="org-ol">
<li>
<code>MPI_THREAD_SINGLE</code> 每个进程一个线程</li>
<li>
<code>MPI_THREAD_FUNNELED</code> 每个进程有多个线程，但只有主线程可以调用 MPI 函数</li>
<li>
<code>MPI_THREAD_SERIALIZED</code> 使用多个线程，每个线程都可以调用 MPI，但是只有一个线程可以调用同步通信</li>
<li>
<code>MPI_THREAD_MULTIPLE</code> 使用多个线程，没有任何限制</li>
</ol>
<p>
使用 <code>MPI_Query_thread()</code> 来确定初始化之后提供的是哪种模式
</p>

<p>
使用 <code>MPI_Is_thread_main()</code> 来确定线程是否是主线程
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org80aa373" class="outline-2">
<h2 id="org80aa373">设计模式</h2>
<div class="outline-text-2" id="text-org80aa373">
</div>
<div id="outline-container-org7db90a3" class="outline-3">
<h3 id="org7db90a3">为每个节点创建一个通信器</h3>
<div class="outline-text-3" id="text-org7db90a3">
<p>
用于创建节点内部的共享内存窗口
</p>

<div class="highlight"><pre><span></span><span class="w">   </span><span class="cm">/* 获得同一节点上的通信器，以及对应的 rank */</span>
<span class="w">   </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm_node</span><span class="p">;</span>
<span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank_node</span><span class="p">;</span>
<span class="w">   </span><span class="n">MPI_Comm_split_type</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_TYPE_SHARED</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INFO_NULL</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">comm_node</span><span class="p">);</span>
<span class="w">   </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm_node</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_rank_node</span><span class="p">);</span>

<span class="w">   </span><span class="cm">/* 获得不同节点上编号为 0 的进程之间的通信器 */</span>
<span class="w">   </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm_0</span><span class="p">;</span>
<span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank_0</span><span class="p">;</span>
<span class="w">   </span><span class="n">MPI_Comm_split</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank_node</span><span class="p">,</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">comm_0</span><span class="p">);</span>
<span class="w">   </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">comm_0</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_rank_0</span><span class="p">);</span>

<span class="w">   </span><span class="n">MPI_Comm_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">comm_node</span><span class="p">);</span>
<span class="w">   </span><span class="n">MPI_Comm_free</span><span class="p">(</span><span class="o">&amp;</span><span class="n">comm_0</span><span class="p">);</span>
</pre></div>
</div>
</div>

<div id="outline-container-orgdd25f32" class="outline-3">
<h3 id="orgdd25f32">非自旋等待</h3>
<div class="outline-text-3" id="text-orgdd25f32">
<ol class="org-ol">
<li>阻塞通信是自旋锁，会一直燃烧 CPU， 为了给某个进程上的多线程任务让出 CPU，需要让其它进程非自旋等待</li>
<li>使用 <code>MPI_Iprobe()</code> 非阻塞地探测信号，并在探测周期中 <code>sleep()</code>
</li>
</ol>
<div class="highlight"><pre><span></span><span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_rank</span><span class="p">;</span>
<span class="w">   </span><span class="n">MPI_Comm_rank</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_rank</span><span class="p">);</span>

<span class="w">   </span><span class="kt">int</span><span class="w"> </span><span class="n">finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">   </span><span class="n">MPI_Request</span><span class="w"> </span><span class="n">finish_request</span><span class="p">;</span>

<span class="w">   </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">proc_rank</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>

<span class="w">       </span><span class="cm">/* do sth pthread or openmp */</span>

<span class="w">       </span><span class="n">finish</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">true</span><span class="p">;</span>
<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">proc_total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">       </span><span class="n">MPI_Comm_size</span><span class="p">(</span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">proc_total</span><span class="p">);</span>
<span class="w">       </span><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">&lt;</span><span class="w"> </span><span class="n">proc_total</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">){</span>
<span class="w">           </span><span class="n">MPI_Isend</span><span class="p">(</span><span class="o">&amp;</span><span class="n">finish</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">finish_request</span><span class="p">);</span>
<span class="w">           </span><span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">finish_request</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">       </span><span class="p">}</span>

<span class="w">   </span><span class="p">}</span><span class="k">else</span><span class="p">{</span>
<span class="w">       </span><span class="kt">int</span><span class="w"> </span><span class="n">flag</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span>
<span class="w">       </span><span class="n">MPI_Status</span><span class="w"> </span><span class="n">finish_status</span><span class="p">;</span>

<span class="w">       </span><span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">flag</span><span class="p">){</span>
<span class="w">           </span><span class="n">MPI_Iprobe</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_ANY_TAG</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">flag</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">finish_status</span><span class="p">);</span>
<span class="w">           </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">flag</span><span class="p">){</span>
<span class="w">               </span><span class="n">MPI_Irecv</span><span class="p">(</span><span class="o">&amp;</span><span class="n">finish</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_INT</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_COMM_WORLD</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">finish_request</span><span class="p">);</span>
<span class="w">               </span><span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">finish_request</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="w">               </span><span class="k">break</span><span class="p">;</span>
<span class="w">           </span><span class="p">}</span>
<span class="w">           </span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">);</span>
<span class="w">       </span><span class="p">}</span>
<span class="w">   </span><span class="p">}</span>
</pre></div>
</div>
</div>

<div id="outline-container-orgaff12f8" class="outline-3">
<h3 id="orgaff12f8">模拟单线程</h3>
<div class="outline-text-3" id="text-orgaff12f8">
<p>
随便写一个变量，按照顺序一个接一个的发送下去
</p>

<div class="highlight"><pre><span></span>   <span class="kn">from</span> <span class="nn">mpi4py</span> <span class="kn">import</span> <span class="n">MPI</span>

   <span class="n">comm</span> <span class="o">=</span> <span class="n">MPI</span><span class="o">.</span><span class="n">COMM_WORLD</span>
   <span class="n">proc_rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_rank</span><span class="p">()</span>
   <span class="n">proc_num</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">Get_size</span><span class="p">()</span>

   <span class="n">myturn</span> <span class="o">=</span> <span class="mi">0</span>

   <span class="k">if</span> <span class="n">proc_rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
       <span class="n">myturn</span> <span class="o">=</span> <span class="mi">1</span>
   <span class="k">else</span><span class="p">:</span>
       <span class="n">myturn</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">recv</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="n">proc_rank</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">proc_rank</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

   <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">proc_rank</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">myturn</span><span class="si">=}</span><span class="s2">"</span><span class="p">)</span>

   <span class="k">if</span> <span class="n">proc_rank</span> <span class="o">&lt;</span> <span class="n">proc_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
       <span class="n">comm</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">myturn</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="n">proc_rank</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="n">proc_rank</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/c/" rel="tag">C</a></li>
            <li><a class="tag p-category" href="../../categories/mpi/" rel="tag">MPI</a></li>
            <li><a class="tag p-category" href="../../categories/parallel/" rel="tag">parallel</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../slepc/" rel="prev" title="SLEPc">上一篇文章</a>
            </li>
            <li class="next">
                <a href="../cython/" rel="next" title="cython">下一篇文章</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>评论</h2>
        
    
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="chimezz",
            disqus_url="https://chimez.github.io/posts/mpi/",
        disqus_title="MPI",
        disqus_identifier="cache/posts/mpi.html",
        disqus_config = function () {
            this.language = "zh_cn";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section></article><script>var disqus_shortname="chimezz";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content--><footer id="footer">
            Contents © 2023         <a href="mailto:chimez@163.com">chimez</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
